# -*- coding: utf-8 -*-
"""Kintsugi Analysis

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RfRWb2flzmzBn7S9OFeJw2yo3SLKMpcA

Let's analyze Kintsugi's vaults and early investors. For that, we will use several subsquids.

Kintsugi-X is a subsquid built by the Kintsugi-X team for the purpose of analysing transfers.
"""

import requests
import json
import pandas as pd

def fetch_from_squid():
    
  kintsugi = "https://api-kusama.interlay.io/graphql/graphql"
  kintsugi_2 = "wss://api-kusama.interlay.io/parachain"
  kusama = "https://app.gc.subsquid.io/beta/kusama-explorer/v1/graphql"
  kintsugi_x = "https://app.gc.subsquid.io/beta/kintsugi-x/v1/graphql"

  """One of the interesting questions is: do vaults self-mint?"""

  def is_equal(row):
      return row["userParachainAddress"] == row['vault.accountId']

  """Let's start creating a directory of interesting Kintsugi addresses.
  This info comes from the Interlay discord server, "meet the vaults".
  """

  kts = {
      "a3eZhSC12zE4D49ir4QkxZwDC3jU6iwNQ953ZZzQsCLTnPJjs": ['Simon Kraus'],
      "a3bccyaV6tCoqaWqByeqvXo5kBbd1m4yCPKyX937HB1APTt7Y": ['rodrigo.barrios', 'hypersphere'],
      "a3bzFrZ5kXYpaaD5NbapUDSfjZPQTWFKGwSbMmGeRAL8BGrCs": ['@boyswan'],
      "a3btcmyVE6ENtWVyHiX9QnorJfKfA2TsSCF43urDeNAWKueH6": ['@seergeist'],
      "a3dh62XsvNmtPAzfwCH9bv34dqPFzjKcWBi5mYM93mKmMt64s": ['@DkA7s'],
      "a3dh7jXhw2q7vqUpEPAb8BeFTNqXXvG9zBf7hsfm3o9hNbjtK": ['@whisperit'],
      "a3aDPraojQvYhVHjyVuYRFXno58EPMjegrY9nubPmpck2X7JS": ['@blinkin', 'chaos DAO'],
      "a3azGTG3qGmUuQckCKjFAhfjfnnRAXmpgV4fPVPziNaA1zCwG": ['@marvel'],
      "a3eKvTxY56smUwHU9vLpw9w5kSqpoPkJskU2tNxUSHAnntQTS": ['@mafux777'],
      "a3cCyigH5pLJXcLKRNGFaBnx3a7diTXq9pPZ1TB8XWgqeCQvW": ['@spazcoin', 'chaos DAO', 'VaaS'],
      "a3baaLbC1JMHJLJ2HwEQMz3S5VuiCWBYy4i66Ziq1vXzmVU6b": ['@spazcoin', 'chaos DAO'],
      "a3fudELrRCjuSyYEPkRAKFQyjzo5YyU228LdqinGsnjBUNB8P": ['@spazcoin', 'chaos DAO', 'VaaS'],
      "a3cCyigH5pLJXcLKRNGFaBnx3a7diTXq9pPZ1TB8XWgqeCQvW": ['@spazcoin', 'chaos DAO'],
      "a3fcMNTjXcJSwAVnTNKwwP7T8XM2bCW7FshsTW2hpUTrdXzed": ['@spazcoin', 'chaos DAO'],
      "a3aPvmjypKaDtjRgYbDL2CCkseYR3SLwvPevL6j7wF67aFtV4": ['@timbotronic'],
      "a3fZSzXxTZYY58BQrfhJx8cDtp4wRdbZ8X4ReF2iUT63y5RcX": ['@0xvault'],
      "a3dJfVzssBJgBmRuMZBre5H71rvawHJoFvFHGz2Aq7Hdt492w": ['@niko'],
      "a3eFe9M2HbAgrQrShEDH2CEvXACtzLhSf4JGkwuT9SQ1EV4ti": ['@paride'],
      "a3cAyFZMgahPoAyWbNRrjX2TnXQtpS3bztCVMNuLNcTYATBte": ['@dan', 'interlay'],
      "a3azPeBMe1EexQvFMd5otaV4q4fPN3Ya5aBQhaChpGzbhLPpe": ['pumpernickel'],
      "a3dMJSmFcqTDpvRPfM2HKn7CHd5uw3G7atogtxXeXru3LGURE": ['@alibaba'],
  }

  """Let's create a query to understand transfers from Kusama (Relay Chain) to Kintsugi. These have to be KSM transfers, because Kusama itself does not handle other assets.
  We assume that all of these will end up as collateral. 

  """

  to_kintsugi = """
  query MyQuery {
    transfers(where: {name_eq: "xcmPallet.reserveTransferAssets", AND: {to: {id_eq: "F7fq1inhrJsYSUkWhyZ3zqtp5K3AKBBjbPWy6VLiRGHipPi"}}}, orderBy: date_DESC) {
      name
      amount
      from {
        id
      }
      date
      to {
        id
      }
    }
  }

  """

  r = requests.post("https://app.gc.subsquid.io/beta/kusama-explorer/v1/graphql", json={"query" : to_kintsugi}).json()
  df_0 = pd.json_normalize(r['data']['transfers'])
  df_0['ksm'] = df_0['amount'].apply(lambda x: float(x) / 1e12)
  kusama_transfers = df_0.groupby('from.id').agg(dict(ksm="sum", date="min")).sort_values('ksm', ascending=False)
  kusama_transfers.reset_index(inplace=True)
  kusama_transfers

  """Now that we know the biggest KSM senders, we should calculate their Kintsugi address. (TO DO IN PYTHON)
  (We use a workaround later)
  """

  redeem_query = """query MyQuery {
    redeems(orderBy: request_timestamp_ASC) {
      id
      request {
        requestedAmountBacking
        timestamp
        height {
          absolute
          active
        }
      }
      userParachainAddress
      vault {
        accountId
        collateralToken
        wrappedToken
      }
      userBackingAddress
      bridgeFee
      btcTransferFee
      collateralPremium
      status
      execution {
        height {
          absolute
          active
        }
        timestamp
      }
      cancellation {
        timestamp
        slashedCollateral
        reimbursed
        height {
          absolute
          active
        }
      }
    }
  }
  """

  """Let's use the official Kintsugi squid to download data about issue requests."""

  issue_query = """
  query MyQuery {
    issues(orderBy: request_timestamp_DESC, limit: 10000, offset: 0) {
      id
      request {
        amountWrapped
        bridgeFeeWrapped
        timestamp
        height {
          absolute
          active
        }
      }
      userParachainAddress
      vault {
        accountId
        collateralToken
        wrappedToken
      }
      vaultBackingAddress
      vaultWalletPubkey
      griefingCollateral
      status
      refund {
        amountPaid
        btcAddress
        btcFee
        executionHeight {
          absolute
          active
        }
        executionTimestamp
        id
        requestHeight {
          absolute
          active
        }
        requestTimestamp
      }
      execution {
        height {
          absolute
          active
        }
        amountWrapped
        bridgeFeeWrapped
        timestamp
      }
      cancellation {
        timestamp
        height {
          absolute
          active
        }
      }
    },
  }
  """

  # Obtain a list of all redemptions and summarize them a bit
  # redeem_query = get_query_text_from_file("redeem")
  r = requests.post(kintsugi, json={"query" : redeem_query}).json()
  df_1 = pd.json_normalize(r['data']['redeems'])
  df_1['btc'] = df_1['request.requestedAmountBacking'].apply(lambda x: float(x) / -1e8)
  df_1['self'] = df_1.apply(is_equal, axis=1)
  df_1['action'] = "redeem"

  # Obtain a list of all issue executions and summarize them a bit
  # issue_query = get_query_text_from_file("issue")
  r = requests.post(kintsugi, json={"query" : issue_query}).json()
  df_2 = pd.json_normalize(r['data']['issues'])
  df_2['btc'] = df_2['request.amountWrapped'].apply(lambda x: float(x) / 1e8)
  df_2['self'] = df_2.apply(is_equal, axis=1)
  df_2['action'] = "issue"

  cols_1 = set(df_1.columns) - set(df_2.columns)
  cols_2 = set(df_2.columns) - set(df_1.columns)

  """Let's create a method to add labels to our list."""

  def add_label_to_list(my_list, label):
    for a in my_list:
      if a not in kts:
        kts[a] = []
      if label not in kts[a]:
        kts[a].append(label)

  """Let's download data about redemptions, so we can net out issues and redemptions for calculating the vault sizes.
  TODO: This analysis should also include Theft and Replacement.
  Since redemptions are negative, the 20% quantile includes the biggest redemptions
  """

  redeems = df_1.groupby('userParachainAddress').agg({'btc':sum}).sort_values('btc', ascending=True)
  redeems['btc'] = redeems.btc.apply(lambda x: -x)
  q = redeems.btc.quantile(.8)
  top_redeemers = redeems[redeems.btc>q].index
  add_label_to_list(top_redeemers, 'Top Redeemer')
  redeems['btc'] = redeems.btc.apply(lambda x: -x)

  issues = df_2.groupby('userParachainAddress').agg({'btc':sum}).sort_values('btc', ascending=False)
  q = issues.btc.quantile(.8)
  top_issues = issues[issues.btc>q].index
  add_label_to_list(top_issues, 'Top Issuer')
  top_issues

  issues[issues.btc>q].btc.sum()

  self_issuers = df_2[df_2.self==True]
  self_issuers.groupby("userParachainAddress").agg(dict(btc=sum)).sort_values("btc", ascending=False)

  """Let's consolidate this info and merge the two dataframes so we can net out the issue requests and the redeem requests."""

  merged_df = pd.concat([
      df_1.loc[df_1.status=='Completed', ['vault.accountId', 'btc', 'request.timestamp']],
      df_2.loc[df_2.status=='Completed', ['vault.accountId', 'btc', 'request.timestamp']],
                        ]).sort_values('request.timestamp')
  biggest_vaults = merged_df.groupby('vault.accountId').agg(dict(btc='sum')).sort_values('btc', ascending=False)
  total_btc = biggest_vaults.btc.sum()
  biggest_vaults['share'] = biggest_vaults.btc.apply(lambda btc: f"{btc/total_btc:.1%}")

  def enrich_df(df, col):
    df[f'label_{col}'] = df[col].apply(lambda v: "/".join(kts.get(v, [])))

  vaults = biggest_vaults.reset_index()
  vaults = vaults.rename(columns={"vault.accountId":"vault"})
  add_label_to_list(list(vaults.vault.iloc[0:20]), "Top 20 Vault")
  add_label_to_list(list(vaults.vault.loc[vaults.vault.isin(self_issuers.userParachainAddress)].iloc[0:20]), "Self Issuer")
  enrich_df(vaults, 'vault')
  vaults.iloc[0:25]

  #from pydrive.auth import GoogleAuth
  #from pydrive.drive import GoogleDrive
  #from google.colab import auth
  #from oauth2client.client import GoogleCredentials

  #auth.authenticate_user()
  #gauth = GoogleAuth()
  #gauth.credentials = GoogleCredentials.get_application_default()
  #drive = GoogleDrive(gauth)

  kintsugix_query="""
  query MyQuery {
    transfers(orderBy: timestamp_DESC) {
      amount
      from {
        karura
        kintsugi
        kusama
        moonriver
        id
      }
      fromChain
      timestamp
      to {
        id
        karura
        kintsugi
        kusama
        moonriver
      }
      toChain
      token
    }
  }

  """

  r = requests.post(kintsugi_x, json={"query" : kintsugix_query}).json()
  xtoken_transfers = pd.json_normalize(r['data']['transfers'])

  master_t = dict(
      KSM = 1e12,
      BTC = 1e8,
      KBTC = 1e8,
      INTR = 1e8, # workaround
      KINT = 1e12,
  )

  def fix_currency(row):
      token = row['token']
      divisor = master_t.get(token, 1.0)
      if token=='INTR': # workaround
          row['kbtc'] = float(row.get('amount', 0.0)) / divisor
      else:
          row[token.lower()] = float(row.get('amount', 0.0)) / divisor
      return row

  """Where did the biggest vaults send their tokens to or receive tokens from?

  Let's see who the vault owners got the KINT from to start
  """



  #x = '10ZVklF3c2NUik_Eldp9QLiUds-A3HDo9'
  #downloaded = drive.CreateFile({'id': x})
  #data=downloaded.GetContentString()
  #import io
  #f = io.StringIO(data)
  #xtoken_transfers = pd.read_csv(f)
  xtoken_transfers.rename(columns={"from.id":"from_id", "to.id":"to_id"}, inplace=True)
  xtoken_transfers = xtoken_transfers.apply(fix_currency, axis=1)
  xtoken_transfers.columns

  xtoken_transfers.timestamp.max()

  """Who are the accounts that have sent KINT to the top 20 vaults?"""

  funding_accounts = xtoken_transfers.loc[
                                          (xtoken_transfers.to_id.isin(vaults.iloc[0:20, 0])) & 
                                          (xtoken_transfers.toChain==2092)
                                          ].groupby(['to_id', 'from_id', 'from.kusama','fromChain']).agg(dict(kint=sum))
  funding_accounts.reset_index(inplace=True)
  add_label_to_list(funding_accounts.from_id, "Likely Vault Owner")
  enrich_df(funding_accounts, 'to_id')
  enrich_df(funding_accounts, 'from_id')
  funding_accounts

  """Of the funders, which ones do we know from the KSM analysis?"""

  # Hard way to create a lookup table from KSM to KINT
  a=xtoken_transfers.groupby(['from.kusama','from_id']).size()
  b = a.reset_index()
  b.index = b['from.kusama']
  del b['from.kusama']

  ksm_to_kint = dict(b['from_id'])

  kusama_transfers.columns

  kusama_transfers['kintsugi'] = kusama_transfers['from.id'].apply(lambda k: ksm_to_kint.get(k, ''))
  k = kusama_transfers.loc[kusama_transfers.ksm>50, 'kintsugi']
  add_label_to_list(k, 'K>50')

  """What do people do with their KBTC?"""



  my_currencies = ['kint', 'ksm', 'kbtc']

  # def add_more_labels(my_currency):
  agg = {}
  for c in my_currencies:
    agg[c] = sum

  agg['timestamp'] = "min"

  top_transfer = xtoken_transfers.groupby(['from_id', 'fromChain','to_id', 'toChain']).agg(agg)
  top_transfer.reset_index(inplace=True)


  for my_currency in my_currencies:
    q = top_transfer[my_currency].quantile(.8)

    top_transfer_ids = top_transfer[top_transfer[my_currency]>q].from_id
    add_label_to_list(top_transfer_ids, f'Top {my_currency.upper()} Mover')

    top_transfer_ids = top_transfer[top_transfer[my_currency]>q].to_id
    add_label_to_list(top_transfer_ids, f'Top {my_currency.upper()} Sink')

  enrich_df(top_transfer, 'from_id')
  enrich_df(top_transfer, 'to_id')

  return top_transfer

  # top_transfer.sort_values('kbtc', ascending=False)

  # """Same story, but with KINT - removing two accounts which seem to be system accounts"""

  # agg['to_id']='nunique'
  # agg['timestamp']='min'
  # xtoken_transfers['last_seen'] = xtoken_transfers.timestamp # workaround to agg this col, too
  # agg['last_seen']='max'

  # top_transfer_from = xtoken_transfers.groupby(['from_id', 'fromChain','toChain']).agg(agg)
  # top_transfer_from.kint = top_transfer_from.kint.apply(lambda k: round(k))
  # top_transfer_from = top_transfer_from.reset_index(inplace=False)

  # exclude = top_transfer_from.sort_values('kint', ascending=False).iloc[0:2, 0]
  # list(exclude)
  # add_label_to_list(exclude, 'KINT System?')

  # top_transfer_from

  # def calc_secs(row):
  #   return (pd.Timestamp(row['last_seen'])-pd.Timestamp(row['timestamp'])) // pd.Timedelta("1s")

  # enrich_df(top_transfer_from, 'from_id')
  # top_transfer_from['duration'] = top_transfer_from.apply(calc_secs, axis=1)
  # # top_transfer_from.loc[top_transfer_from.kbtc>0.025].sort_values('duration', ascending=False)
  # top_transfer_from.sort_values('duration', ascending=False)
  # # top_transfer_from.sort_values('timestamp', ascending=True)

  # xtoken_transfers.loc[~xtoken_transfers.from_id.isin(exclude)]

  # top_transfer_from = top_transfer_from.groupby(['from_id', 'fromChain','toChain']).agg(agg)
  # top_transfer_from.kint = top_transfer_from.kint.apply(lambda k: round(k))
  # top_transfer_from.reset_index(inplace=True)

  # enrich_df(top_transfer_from, 'from_id')
  # top_transfer_from.loc[top_transfer_from.kint>q].sort_values('kint', ascending=False)

  # s=top_transfer_from[my_currency].sum()
  # top_transfer_from['percentage'] = (top_transfer_from.kint / s) * 100
  # top_transfer_from.sort_values('kint', ascending=False)

  # my_currency = 'kint'
  # top_transfer.sort_values(my_currency, ascending=False, inplace=True)
  # top_transfer[my_currency] = top_transfer[my_currency].apply(lambda c: round(c, 0)) 
  # #top_transfer['kint'] = top_transfer['kint'].apply(lambda c: round(c, 3)) 
  # top_transfer

  # """What do these funding accounts do with their BTC?"""

  # my_currency = 'kbtc'
  # xtoken_transfers.loc[xtoken_transfers.from_id.isin(vaults_or_owners)].groupby(['from_id', 'fromChain','to_id', 'toChain']).agg({my_currency : sum}).sort_values(my_currency, ascending=False)

  # my_currency = 'kint'
  # xtoken_transfers[my_currency] = xtoken_transfers[my_currency].apply(lambda x: round(x) if pd.notnull(x) else 0)
  # xtoken_transfers.loc[xtoken_transfers.from_id.isin(vaults_or_owners)].groupby(['from_id', 'fromChain','to_id', 'toChain']).agg({my_currency : sum}).sort_values(my_currency, ascending=False)

  # xtoken_transfers.loc[xtoken_transfers.from_id.isin(vaults.iloc[0:10, 0])].groupby(['from_id', 'to_id']).agg(dict(kbtc=sum))

  # xtoken_transfers.loc[xtoken_transfers.from_id.isin(funding_accounts)].groupby(['from_id', 'to_id']).agg(dict(kbtc=sum))